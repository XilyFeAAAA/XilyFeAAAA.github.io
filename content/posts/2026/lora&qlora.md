---
title: LoRA&QLoRA
date: 2026-02-16T20:21:20+08:00
featuredImage: http://img.xilyfe.top/img/20260216202310375.png
authors:
  - Xilyfe
series:
  - LLM
tags:
  - 大模型
lastmod: 2026-02-17T03:19:39+08:00
---
## 为什么需要 QLoRA

随着 LLM 参数量不断攀升，全量微调所需的显存越来越大。所以出现了 LoRA，它的思路是：冻结主模型权重，只训练少量的低秩适配器。这样虽然需要加载整个模型到显卡，但是由于只需要训练 LoRA 的 $A$ 和 $B$ 两个权重矩阵，所以优化器的参数非常少，并且中间激活值的占用也大幅度减小，所以显存需求大幅降低。

但加载模型本身仍需高精度，显存占用依然较大。QLoRA 的思路就是在 LoRA 的基础上，将预训练模型量化为 4-bit，进一步压缩显存占用

## 核心原理


## Qwen3 QLoRA 实践
