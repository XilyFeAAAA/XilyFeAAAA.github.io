---
title: 分布式训练技术
date: 2026-02-02T19:50:43+08:00
featuredImage: http://img.xilyfe.top/img/20260202195145685.png
authors:
  - Xilyfe
series:
  - LLM
tags: []
lastmod: 2026-02-02T09:11:19+08:00
---
我们先回忆一下传统的单机单卡训练模式：

![image.png](http://img.xilyfe.top/img/20260202195324965.png)
首先硬盘读取数据，CPU 处理数据，将数据组成一个 batch，再传入 GPU，网络前向传播算出 loss，再反向传播计算梯度，用梯度更新参数完成一次训练。这种传统模式在大参数量或者大数据量的情况下就容易陷入显存的瓶颈，于是就引出了多卡并行训练。

## DP


![image.png](http://img.xilyfe.top/img/20260202195640665.png)
DP(Data Parallel)，也就是数据并行。它的运行模式是：
1. 硬盘读取数据，由 CPU 处理之后，给每个 GPU 传不同的一部分 mini batch
2. 每个 GPU 各自计算进行前向传播，计算损失函数，然后反向传播计算梯度
3. 其它每个 GPU 都把梯度传给 GPU-0，计算全局平均梯度，然后更新自己的参数
4. 最后 GPU-0 把最新的参数传给其它 GPU，保证所有 GPU 上模型的一致。

Data Parallel 的问题在于数据的传输量太大了，并且都集中在 GPU-0 上压力太大了。假设参数量为 $\Psi$ 节点数量为 $N$，那么 GPU-0 需要传入梯度 $(N-1)\Psi$，传出参数量为 $(N-1)\Psi$；其他 GPU 传出梯度量为 $\Psi$ 传入参数为 $\Psi$。其次 DP 模型中给每个 GPU 分配一个线程，这就会出现 GIL 锁的问题。每个 GPU 所在线程进行前向计算或者反向传播时候，由于执行的是 CUDA 内核所以会解开 GIL 锁。但是 DP 里面还有很多纯 Python 层面的代码，例如模型复制 、输入切分、输出收集等等，这些操作由于 GIL 锁的存在就不能并行执行，效率很低。


## DDP

